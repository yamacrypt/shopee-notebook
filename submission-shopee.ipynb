{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cooked-conviction",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T06:28:37.633278Z",
     "iopub.status.busy": "2021-05-10T06:28:37.632545Z",
     "iopub.status.idle": "2021-05-10T06:29:41.008582Z",
     "shell.execute_reply": "2021-05-10T06:29:41.007364Z"
    },
    "papermill": {
     "duration": 63.411955,
     "end_time": "2021-05-10T06:29:41.008747",
     "exception": false,
     "start_time": "2021-05-10T06:28:37.596792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/shopee-external-models/Keras_Applications-1.0.8-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from Keras-Applications==1.0.8) (1.19.5)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from Keras-Applications==1.0.8) (2.10.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->Keras-Applications==1.0.8) (1.15.0)\r\n",
      "Installing collected packages: Keras-Applications\r\n",
      "Successfully installed Keras-Applications-1.0.8\r\n",
      "Processing /kaggle/input/shopee-external-models/efficientnet-1.1.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /opt/conda/lib/python3.7/site-packages (from efficientnet==1.1.0) (1.0.8)\r\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (from efficientnet==1.1.0) (0.18.1)\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.1.0) (1.19.5)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.1.0) (2.10.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet==1.1.0) (1.15.0)\r\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (3.4.0)\r\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (2021.3.17)\r\n",
      "Requirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (2.9.0)\r\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (2.5)\r\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (1.1.1)\r\n",
      "Requirement already satisfied: scipy>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (1.5.4)\r\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (7.2.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (2.8.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (0.10.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (2.4.7)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->efficientnet==1.1.0) (4.4.2)\r\n",
      "Installing collected packages: efficientnet\r\n",
      "Successfully installed efficientnet-1.1.0\r\n"
     ]
    }
   ],
   "source": [
    "from kaggle_datasets import KaggleDatasets\n",
    "!pip install ../input/shopee-external-models/Keras_Applications-1.0.8-py3-none-any.whl\n",
    "!pip install ../input/shopee-external-models/efficientnet-1.1.0-py3-none-any.whl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import cudf\n",
    "import cuml\n",
    "import cupy\n",
    "from cuml.feature_extraction.text import TfidfVectorizer\n",
    "from cuml import PCA\n",
    "from cuml.neighbors import NearestNeighbors\n",
    "import tensorflow as tf\n",
    "import efficientnet.tfkeras as efn\n",
    "from tqdm.notebook import tqdm\n",
    "import math\n",
    "from shutil import copyfile\n",
    "\n",
    "copyfile(src = \"../input/shopee-external-models/tokenization.py\", dst = \"../working/tokenization.py\")\n",
    "import tokenization\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "choice-stock",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T06:29:41.071212Z",
     "iopub.status.busy": "2021-05-10T06:29:41.069412Z",
     "iopub.status.idle": "2021-05-10T06:29:41.071808Z",
     "shell.execute_reply": "2021-05-10T06:29:41.072198Z"
    },
    "papermill": {
     "duration": 0.038535,
     "end_time": "2021-05-10T06:29:41.072323",
     "exception": false,
     "start_time": "2021-05-10T06:29:41.033788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For tf.dataset\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# Configuration\n",
    "BATCH_SIZE = 8\n",
    "IMAGE_SIZE = [512, 512]\n",
    "# Seed\n",
    "SEED = 42\n",
    "# Verbosity\n",
    "VERBOSE = 1\n",
    "\"\"\"Settings\"\"\"\n",
    "# Number of classes\n",
    "N_CLASSES = 11014\n",
    "#how to ensemble matchs result \n",
    "CONCAT=True\n",
    "#image_model_weight_path0='../input/shopee-adacos-fold/eff_adacos_model_fold0.h5'\n",
    "image_model_weight_path1='../input/effnetb3adacos/EfficientNetB3_adacos_512_42.h5'\n",
    "image_model_weight_path2='../input/effnetb4adacos/EfficientNetB4_adacos_512_42.h5'\n",
    "#image_model_weight_path3='../input/shopee-adacos-fold/eff_adacos_model_fold3.h5'\n",
    "image_model_weight_sam='../input/shopepeeffnetadacossam/EfficientNetB5_sam_adacos_512_42 (1).h5'\n",
    "text_model_weight_path0='../input/shopee-bert-adacos/bert-arcface.h5'\n",
    "# Flag to get cv score\n",
    "GET_CV = False\n",
    "image_output_layer=-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-plane",
   "metadata": {
    "papermill": {
     "duration": 0.023982,
     "end_time": "2021-05-10T06:29:41.120478",
     "exception": false,
     "start_time": "2021-05-10T06:29:41.096496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "brilliant-upset",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T06:29:41.396736Z",
     "iopub.status.busy": "2021-05-10T06:29:41.395865Z",
     "iopub.status.idle": "2021-05-10T06:29:46.150797Z",
     "shell.execute_reply": "2021-05-10T06:29:46.150255Z"
    },
    "papermill": {
     "duration": 5.005728,
     "end_time": "2021-05-10T06:29:46.150989",
     "exception": false,
     "start_time": "2021-05-10T06:29:41.145261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will restrict TensorFlow to max 8GB GPU RAM\n",
      "then RAPIDS can use 8GB GPU RAM\n"
     ]
    }
   ],
   "source": [
    "# RESTRICT TENSORFLOW TO 2GB OF GPU RAM\n",
    "# SO THAT WE HAVE 14GB RAM FOR RAPIDS\n",
    "LIMIT = 8.0\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*LIMIT)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        #print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "print('We will restrict TensorFlow to max %iGB GPU RAM'%LIMIT)\n",
    "print('then RAPIDS can use %iGB GPU RAM'%(16-LIMIT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rough-recorder",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T06:29:46.208704Z",
     "iopub.status.busy": "2021-05-10T06:29:46.206895Z",
     "iopub.status.idle": "2021-05-10T06:29:46.216875Z",
     "shell.execute_reply": "2021-05-10T06:29:46.216386Z"
    },
    "papermill": {
     "duration": 0.041204,
     "end_time": "2021-05-10T06:29:46.216996",
     "exception": false,
     "start_time": "2021-05-10T06:29:46.175792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Flag to check ram allocations (debug)\n",
    "CHECK_SUB = False\n",
    "from tensorflow.keras import backend as K\n",
    "df = pd.read_csv('../input/shopee-product-matching/test.csv')\n",
    "# If we are comitting, replace train set for test set and dont get cv\n",
    "if len(df) > 3:\n",
    "    GET_CV = False\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "rural-parade",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T06:29:46.276074Z",
     "iopub.status.busy": "2021-05-10T06:29:46.274549Z",
     "iopub.status.idle": "2021-05-10T06:29:46.277126Z",
     "shell.execute_reply": "2021-05-10T06:29:46.277522Z"
    },
    "papermill": {
     "duration": 0.034213,
     "end_time": "2021-05-10T06:29:46.277681",
     "exception": false,
     "start_time": "2021-05-10T06:29:46.243468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "def get_valid():\n",
    "    seed_everything(SEED)\n",
    "    print('\\n')\n",
    "    print('-'*50)\n",
    "    train, valid = train_test_split(TRAINING_FILENAMES, shuffle = True, random_state = SEED)\n",
    "    return valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "painted-softball",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T06:29:46.334294Z",
     "iopub.status.busy": "2021-05-10T06:29:46.333584Z",
     "iopub.status.idle": "2021-05-10T06:29:46.336463Z",
     "shell.execute_reply": "2021-05-10T06:29:46.336044Z"
    },
    "papermill": {
     "duration": 0.034194,
     "end_time": "2021-05-10T06:29:46.336600",
     "exception": false,
     "start_time": "2021-05-10T06:29:46.302406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.python.keras.utils import tf_utils\n",
    "\n",
    "\n",
    "def _resolve_training(layer, training):\n",
    "    if training is None:\n",
    "        training = K.learning_phase()\n",
    "    if isinstance(training, int):\n",
    "        training = bool(training)\n",
    "    if not layer.trainable:\n",
    "        # When the layer is not trainable, override the value\n",
    "        training = False\n",
    "    return training#tf_utils.constant_value(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "strategic-knight",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T06:29:46.402085Z",
     "iopub.status.busy": "2021-05-10T06:29:46.401308Z",
     "iopub.status.idle": "2021-05-10T06:29:46.404111Z",
     "shell.execute_reply": "2021-05-10T06:29:46.403714Z"
    },
    "papermill": {
     "duration": 0.042272,
     "end_time": "2021-05-10T06:29:46.404220",
     "exception": false,
     "start_time": "2021-05-10T06:29:46.361948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras.layers\n",
    "class AdaCos(Layer):\n",
    "    \"\"\"\n",
    "    Implementation of AdaCos layer. Reference: https://arxiv.org/abs/1905.00292\n",
    "    \n",
    "    Arguments:\n",
    "      num_classes: number of classes to classify\n",
    "      is_dynamic: if False, use Fixed AdaCos. Else, use Dynamic Adacos.\n",
    "      regularizer: weights regularizer\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 num_classes,\n",
    "                 is_dynamic=True,\n",
    "                 regularizer=None,\n",
    "                 **kwargs):\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "        self._n_classes = num_classes\n",
    "        self._init_s = math.sqrt(2) * math.log(num_classes - 1)\n",
    "        self._is_dynamic = is_dynamic\n",
    "        self._regularizer = regularizer\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        embedding_shape, label_shape = input_shape\n",
    "        self._w = self.add_weight(name='W',shape=(embedding_shape[-1], self._n_classes),\n",
    "                                  initializer='glorot_uniform',\n",
    "                                  trainable=True,\n",
    "                                  regularizer=self._regularizer)\n",
    "        if self._is_dynamic:\n",
    "            self._s = self.add_weight(name='S',shape=(),\n",
    "                                      initializer=Constant(self._init_s),\n",
    "                                      trainable=False,\n",
    "                                      aggregation=tf.VariableAggregation.MEAN)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        embedding, label = inputs\n",
    "        label = tf.cast(label, dtype=tf.int32)\n",
    "\n",
    "        # Squeezing is necessary for Keras. It expands the dimension to (n, 1)\n",
    "        label = tf.reshape(label, [-1])\n",
    "\n",
    "        # Normalize features and weights and compute dot product\n",
    "        x = tf.nn.l2_normalize(embedding, axis=1)\n",
    "        w = tf.nn.l2_normalize(self._w, axis=0)\n",
    "        logits = tf.matmul(x, w)\n",
    "\n",
    "        # Fixed AdaCos\n",
    "        is_dynamic = self._is_dynamic#tf_utils.constant_value(self._is_dynamic)\n",
    "        if not is_dynamic:\n",
    "            # _s is not created since we are not in dynamic mode\n",
    "            output = tf.multiply(self._init_s, logits)\n",
    "            return output\n",
    "\n",
    "        training = _resolve_training(self, training)\n",
    "        if not training:\n",
    "            # We don't have labels to update _s if we're not in training mode\n",
    "            return self._s * logits\n",
    "        else:\n",
    "            theta = tf.math.acos(\n",
    "                    K.clip(logits, -1.0 + K.epsilon(), 1.0 - K.epsilon()))\n",
    "            one_hot = tf.one_hot(label, depth=self._n_classes)\n",
    "            b_avg = tf.where(one_hot < 1.0,\n",
    "                             tf.exp(self._s * logits),\n",
    "                             tf.zeros_like(logits))\n",
    "            b_avg = tf.reduce_mean(tf.reduce_sum(b_avg, axis=1))\n",
    "            theta_class = tf.gather_nd(\n",
    "                    theta,\n",
    "                    tf.stack([\n",
    "                        tf.range(tf.shape(label)[0]),\n",
    "                        tf.cast(label, tf.int32)\n",
    "                    ], axis=1))\n",
    "            mid_index = tf.shape(theta_class)[0] // 2 + 1\n",
    "            theta_med = tf.nn.top_k(theta_class, mid_index).values[-1]\n",
    "\n",
    "            # Since _s is not trainable, this assignment is safe. Also,\n",
    "            # tf.function ensures that this will run in the right order.\n",
    "            self._s.assign(\n",
    "                    tf.math.log(b_avg) /\n",
    "                    tf.math.cos(tf.minimum(math.pi/4, theta_med)))\n",
    "\n",
    "            # Return scaled logits\n",
    "            return self._s * logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "broke-peeing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T06:29:46.483296Z",
     "iopub.status.busy": "2021-05-10T06:29:46.462497Z",
     "iopub.status.idle": "2021-05-10T06:29:46.499813Z",
     "shell.execute_reply": "2021-05-10T06:29:46.499357Z"
    },
    "papermill": {
     "duration": 0.070678,
     "end_time": "2021-05-10T06:29:46.499918",
     "exception": false,
     "start_time": "2021-05-10T06:29:46.429240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to get our f1 score\n",
    "def f1_score(y_true, y_pred):\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
    "    len_y_pred = y_pred.apply(lambda x: len(x)).values\n",
    "    len_y_true = y_true.apply(lambda x: len(x)).values\n",
    "    f1 = 2 * intersection / (len_y_pred + len_y_true)\n",
    "    return f1\n",
    "\n",
    "# Function to combine predictions\n",
    "def combine_predictions(row):\n",
    "    if CONCAT:\n",
    "        x = np.concatenate([row['image_predictions'], row['text_predictions']])\n",
    "    else:\n",
    "        x = np.intersect1d(row['image_predictions'], row['text_predictions'])\n",
    "    return ' '.join( np.unique(x) )\n",
    "\n",
    "# Function to read out dataset\n",
    "def read_dataset():\n",
    "    if GET_CV:\n",
    "        df = pd.read_csv('../input/shopee-product-matching/train.csv')\n",
    "        tmp = df.groupby(['label_group'])['posting_id'].unique().to_dict()\n",
    "        df['matches'] = df['label_group'].map(tmp)\n",
    "        df['matches'] = df['matches'].apply(lambda x: ' '.join(x))\n",
    "        if CHECK_SUB:\n",
    "            df = pd.concat([df, df], axis = 0)\n",
    "            df.reset_index(drop = True, inplace = True)\n",
    "        df_cu = cudf.DataFrame(df)\n",
    "        image_paths = '../input/shopee-product-matching/train_images/' + df['image']\n",
    "    else:\n",
    "        df = pd.read_csv('../input/shopee-product-matching/test.csv')\n",
    "        df_cu = cudf.DataFrame(df)\n",
    "        image_paths = '../input/shopee-product-matching/test_images/' + df['image']\n",
    "        \n",
    "    return df, df_cu, image_paths\n",
    "\n",
    "# Function to decode our images\n",
    "def decode_image(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels = 3)\n",
    "    image = tf.image.resize(image, IMAGE_SIZE)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image\n",
    "\n",
    "# Function to read our test image and return image\n",
    "def read_image(image):\n",
    "    image = tf.io.read_file(image)\n",
    "    image = decode_image(image)\n",
    "    return image\n",
    "\n",
    "# Function to get our dataset that read images\n",
    "def get_dataset(image):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(image)\n",
    "    dataset = dataset.map(read_image, num_parallel_calls = AUTO)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset\n",
    "\n",
    "# Arcmarginproduct class keras layer\n",
    "class ArcMarginProduct(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    Implements large margin arc distance.\n",
    "\n",
    "    Reference:\n",
    "        https://arxiv.org/pdf/1801.07698.pdf\n",
    "        https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/\n",
    "            blob/master/src/modeling/metric_learning.py\n",
    "    '''\n",
    "    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n",
    "                 ls_eps=0.0, **kwargs):\n",
    "\n",
    "        super(ArcMarginProduct, self).__init__(**kwargs)\n",
    "\n",
    "        self.n_classes = n_classes\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.ls_eps = ls_eps\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = tf.math.cos(m)\n",
    "        self.sin_m = tf.math.sin(m)\n",
    "        self.th = tf.math.cos(math.pi - m)\n",
    "        self.mm = tf.math.sin(math.pi - m) * m\n",
    "\n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'n_classes': self.n_classes,\n",
    "            's': self.s,\n",
    "            'm': self.m,\n",
    "            'ls_eps': self.ls_eps,\n",
    "            'easy_margin': self.easy_margin,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(ArcMarginProduct, self).build(input_shape[0])\n",
    "\n",
    "        self.W = self.add_weight(\n",
    "            name='W',\n",
    "            shape=(int(input_shape[0][-1]), self.n_classes),\n",
    "            initializer='glorot_uniform',\n",
    "            dtype='float32',\n",
    "            trainable=True,\n",
    "            regularizer=None)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        X, y = inputs\n",
    "        y = tf.cast(y, dtype=tf.int32)\n",
    "        cosine = tf.matmul(\n",
    "            tf.math.l2_normalize(X, axis=1),\n",
    "            tf.math.l2_normalize(self.W, axis=0)\n",
    "        )\n",
    "        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = tf.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        one_hot = tf.cast(\n",
    "            tf.one_hot(y, depth=self.n_classes),\n",
    "            dtype=cosine.dtype\n",
    "        )\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n",
    "\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "        return output\n",
    "\n",
    "# Function to get the embeddings of our images with the fine-tuned model\n",
    "def get_image_embeddings(image_paths,weight_path):\n",
    "    embeds = []\n",
    "    K.clear_session()\n",
    "    adacos=AdaCos(N_CLASSES, name='AdaCos' )\n",
    "    inp = tf.keras.layers.Input(shape = (*IMAGE_SIZE, 3), name = 'inp1')\n",
    "    label = tf.keras.layers.Input(shape = (), name = 'inp2')\n",
    "    x = efn.EfficientNetB5(weights = None, include_top = False)(inp)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = adacos((x,label),False)#margin([x, label])\n",
    "    output = tf.keras.layers.Softmax(dtype='float32')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs = [inp, label], outputs = [output])\n",
    "    #model.summary()\n",
    "    #model.load_weights('../input/shopee-effnet-arcface/EfficientNetB5_arcface_512_42 (1).h5')\n",
    "    model.load_weights(weight_path)\n",
    "    model = tf.keras.models.Model(inputs = model.input[0], outputs = model.layers[image_output_layer].output)\n",
    "    chunk = 5000\n",
    "    iterator = np.arange(np.ceil(len(df) / chunk))\n",
    "    for j in iterator:\n",
    "        a = int(j * chunk)\n",
    "        b = int((j + 1) * chunk)\n",
    "        image_dataset = get_dataset(image_paths[a:b])\n",
    "        image_embeddings = model.predict(image_dataset)\n",
    "        embeds.append(image_embeddings)\n",
    "    del model\n",
    "    image_embeddings = np.concatenate(embeds)\n",
    "    print(f'Our image embeddings shape is {image_embeddings.shape}')\n",
    "    del embeds\n",
    "    gc.collect()\n",
    "    return image_embeddings\n",
    "def get_image_embeddingsb3(image_paths,weight_path):\n",
    "    embeds = []\n",
    "    K.clear_session()\n",
    "    adacos=AdaCos(N_CLASSES, name='AdaCos' )\n",
    "    inp = tf.keras.layers.Input(shape = (*IMAGE_SIZE, 3), name = 'inp1')\n",
    "    label = tf.keras.layers.Input(shape = (), name = 'inp2')\n",
    "    x = efn.EfficientNetB3(weights = None, include_top = False)(inp)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = adacos((x,label),False)#margin([x, label])\n",
    "    output = tf.keras.layers.Softmax(dtype='float32')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs = [inp, label], outputs = [output])\n",
    "    #model.summary()\n",
    "    #model.load_weights('../input/shopee-effnet-arcface/EfficientNetB5_arcface_512_42 (1).h5')\n",
    "    model.load_weights(weight_path)\n",
    "    model = tf.keras.models.Model(inputs = model.input[0], outputs = model.layers[image_output_layer].output)\n",
    "    chunk = 5000\n",
    "    iterator = np.arange(np.ceil(len(df) / chunk))\n",
    "    for j in iterator:\n",
    "        a = int(j * chunk)\n",
    "        b = int((j + 1) * chunk)\n",
    "        image_dataset = get_dataset(image_paths[a:b])\n",
    "        image_embeddings = model.predict(image_dataset)\n",
    "        embeds.append(image_embeddings)\n",
    "    del model\n",
    "    image_embeddings = np.concatenate(embeds)\n",
    "    print(f'Our image embeddings shape is {image_embeddings.shape}')\n",
    "    del embeds\n",
    "    gc.collect()\n",
    "    return image_embeddings\n",
    "def get_image_embeddingsb4(image_paths,weight_path):\n",
    "    embeds = []\n",
    "    K.clear_session()\n",
    "    adacos=AdaCos(N_CLASSES, name='AdaCos' )\n",
    "    inp = tf.keras.layers.Input(shape = (*IMAGE_SIZE, 3), name = 'inp1')\n",
    "    label = tf.keras.layers.Input(shape = (), name = 'inp2')\n",
    "    x = efn.EfficientNetB4(weights = None, include_top = False)(inp)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = adacos((x,label),False)#margin([x, label])\n",
    "    output = tf.keras.layers.Softmax(dtype='float32')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs = [inp, label], outputs = [output])\n",
    "    #model.summary()\n",
    "    #model.load_weights('../input/shopee-effnet-arcface/EfficientNetB5_arcface_512_42 (1).h5')\n",
    "    model.load_weights(weight_path)\n",
    "    model = tf.keras.models.Model(inputs = model.input[0], outputs = model.layers[image_output_layer].output)\n",
    "    chunk = 5000\n",
    "    iterator = np.arange(np.ceil(len(df) / chunk))\n",
    "    for j in iterator:\n",
    "        a = int(j * chunk)\n",
    "        b = int((j + 1) * chunk)\n",
    "        image_dataset = get_dataset(image_paths[a:b])\n",
    "        image_embeddings = model.predict(image_dataset)\n",
    "        embeds.append(image_embeddings)\n",
    "    del model\n",
    "    image_embeddings = np.concatenate(embeds)\n",
    "    print(f'Our image embeddings shape is {image_embeddings.shape}')\n",
    "    del embeds\n",
    "    gc.collect()\n",
    "    return image_embeddings\n",
    "\n",
    "# Return tokens, masks and segments from a text array or series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "english-thickness",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T06:29:46.554282Z",
     "iopub.status.busy": "2021-05-10T06:29:46.553743Z",
     "iopub.status.idle": "2021-05-10T06:29:48.426285Z",
     "shell.execute_reply": "2021-05-10T06:29:48.425193Z"
    },
    "papermill": {
     "duration": 1.901503,
     "end_time": "2021-05-10T06:29:48.426512",
     "exception": false,
     "start_time": "2021-05-10T06:29:46.525009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,BertTokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "tokenizer = BertTokenizer.from_pretrained('../input/bert-tokenizer/tokenizer')\n",
    "#tokenizer.save_pretrained('tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "asian-infection",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T06:29:48.505447Z",
     "iopub.status.busy": "2021-05-10T06:29:48.504486Z",
     "iopub.status.idle": "2021-05-10T06:29:48.619774Z",
     "shell.execute_reply": "2021-05-10T06:29:48.619281Z"
    },
    "papermill": {
     "duration": 0.165691,
     "end_time": "2021-05-10T06:29:48.619893",
     "exception": false,
     "start_time": "2021-05-10T06:29:48.454202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TFM_PATH = 'bert-base-uncased'\n",
    "from transformers import AutoTokenizer, TFAutoModel ,TFBertModel\n",
    "class RobertaArcFace(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.roberta = TFAutoModel.from_pretrained(TFM_PATH)\n",
    "        adacos=AdaCos(N_CLASSES, name='AdaCos' ) \n",
    "        self.arc_margin =adacos\n",
    "        self.softmax = tf.keras.layers.Softmax(dtype='float32')\n",
    "    def call(self, inputs):\n",
    "        tokens, masks, labels = inputs\n",
    "        out = self.roberta(tokens, masks)\n",
    "        feats = out.last_hidden_state[:, 0, :]\n",
    "        out = self.arc_margin((feats, labels),False)\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "def bert_encode(texts, tokenizer, max_len=512):\n",
    "    all_tokens = []\n",
    "    all_masks = []\n",
    "    all_segments = []\n",
    "    \n",
    "    for text in texts:\n",
    "        text = tokenizer.tokenize(text)\n",
    "            \n",
    "        text = text[:max_len-2]\n",
    "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
    "        pad_len = max_len - len(input_sequence)\n",
    "        \n",
    "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
    "        tokens += [0] * pad_len\n",
    "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
    "        segment_ids = [0] * max_len\n",
    "        \n",
    "        all_tokens.append(tokens)\n",
    "        all_masks.append(pad_masks)\n",
    "        all_segments.append(segment_ids)\n",
    "    \n",
    "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)\n",
    "\n",
    "def tokenize(df):\n",
    "    inputs = tokenizer(df.title.tolist(), return_tensors='tf', max_length=64, padding='max_length', truncation=True)\n",
    "    return inputs['input_ids'].numpy(), inputs['attention_mask'].numpy()\n",
    "def load_df():\n",
    "    if GET_CV:\n",
    "        test_df = pd.read_csv('../input/shopee-product-matching/train.csv')\n",
    "    else:\n",
    "        test_df = pd.read_csv('../input/shopee-product-matching/test.csv')\n",
    "    #test_df = pd.read_csv('../input/shopee-product-matching/train.csv')\n",
    "    #test_df['label_group'] = LabelEncoder().fit_transform(test_df['label_group'])\n",
    "    #N_CLASSES = test_df['label_group'].nunique()\n",
    "    #train_x, valid_x = train_test_split(train_df[['title', 'label_group']], shuffle=True, stratify=train_df['label_group'], random_state=SEED, test_size=0.33)\n",
    "    return test_df[['title']]#, 'label_group']]#train_x, valid_x\n",
    "def load_ds(tokens, masks, labels):\n",
    "    text_ds = tf.data.Dataset.from_tensor_slices((tokens, masks, labels))\n",
    "    label_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
    "    ds = tf.data.Dataset.zip((text_ds, label_ds))\n",
    "    return ds\n",
    "def load():\n",
    "    test_df = load_df()\n",
    "    test_x = tokenize(test_df)\n",
    "    #test_ds['input_ids']=test_x[0]\n",
    "    #test_ds['attention_mask']=test_x[1]\n",
    "    #test_ds = load_ds(*test_x, test_df.label_group.values)\n",
    "    return test_x[0],test_x[1]#,test_df['label_group'].to_numpy()\n",
    "# Function to get our text title embeddings using a pre-trained bert model\n",
    "def get_text_embeddings(text_model_weight_path,max_len = 64):\n",
    "    embeds = []\n",
    "    K.clear_session()\n",
    "    #module_url = \"../input/shopee-external-models/bert_en_uncased_L-24_H-1024_A-16_1\"\n",
    "    #bert_layer = hub.KerasLayer(module_url, trainable = True)\n",
    "    #vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "    #do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "    #tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)\n",
    "    #text = bert_encode(df['title'].values, tokenizer, max_len = max_len)\n",
    "\n",
    "    text=load()\n",
    "    K.clear_session()\n",
    "    roberta=TFBertModel.from_pretrained('../input/base-bert-model/base_bert')\n",
    "    adacos=AdaCos(N_CLASSES, name='AdaCos' ) \n",
    "    softmax= tf.keras.layers.Softmax(dtype='float32')\n",
    "    tokens = tf.keras.layers.Input(shape = (max_len,), dtype=tf.int32, name = 'tokens')\n",
    "    masks  = tf.keras.layers.Input(shape = (max_len,), dtype=tf.int32, name = 'masks')\n",
    "    labels = tf.keras.layers.Input(shape = (), name = 'label')\n",
    "    out = roberta(tokens, masks)\n",
    "    feats = out.last_hidden_state[:, 0, :]\n",
    "    out = adacos((feats, labels),False)\n",
    "    out = softmax(out)\n",
    "    model = tf.keras.models.Model(inputs = [tokens,masks, labels], outputs = [out])\n",
    "    #model = RobertaArcFace()#([tokens,masks,labels])\n",
    "    model.load_weights(text_model_weight_path)\n",
    "    model = tf.keras.models.Model(inputs = model.input[0:2], outputs = model.layers[-4].output)\n",
    "    chunk = 5000\n",
    "    iterator = np.arange(np.ceil(len(text[0]) / chunk))\n",
    "    for j in iterator:\n",
    "        a = int(j * chunk)\n",
    "        b = int((j + 1) * chunk)\n",
    "        text_chunk = ((text[0][a:b], text[1][a:b]))\n",
    "        text_embeddings = model.predict(text_chunk, batch_size = BATCH_SIZE)\n",
    "        embeds.append(text_embeddings)\n",
    "    del model\n",
    "    text_embeddings = np.concatenate(embeds)\n",
    "    print(f'Our text embeddings shape is {text_embeddings.shape}')\n",
    "    del embeds\n",
    "    gc.collect()\n",
    "    return text_embeddings\n",
    "    \n",
    "# Function to get 50 nearest neighbors of each image and apply a distance threshold to maximize cv\n",
    "def get_simple_text_embeddings(max_features = 25_000):\n",
    "    model = TfidfVectorizer(stop_words = 'english', binary = True, max_features = max_features)\n",
    "    text_embeddings = model.fit_transform(df_cu['title']).toarray()\n",
    "    del model\n",
    "    gc.collect()\n",
    "    return text_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-pledge",
   "metadata": {
    "papermill": {
     "duration": 0.026697,
     "end_time": "2021-05-10T06:29:48.673895",
     "exception": false,
     "start_time": "2021-05-10T06:29:48.647198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "decent-childhood",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T06:29:48.739348Z",
     "iopub.status.busy": "2021-05-10T06:29:48.731797Z",
     "iopub.status.idle": "2021-05-10T06:29:52.778954Z",
     "shell.execute_reply": "2021-05-10T06:29:52.778432Z"
    },
    "papermill": {
     "duration": 4.07858,
     "end_time": "2021-05-10T06:29:52.779101",
     "exception": false,
     "start_time": "2021-05-10T06:29:48.700521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df, df_cu, image_paths = read_dataset()\n",
    "df[['posting_id']].to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "british-brick",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T06:29:52.838709Z",
     "iopub.status.busy": "2021-05-10T06:29:52.838010Z",
     "iopub.status.idle": "2021-05-10T06:30:25.182923Z",
     "shell.execute_reply": "2021-05-10T06:30:25.182429Z"
    },
    "papermill": {
     "duration": 32.376338,
     "end_time": "2021-05-10T06:30:25.183059",
     "exception": false,
     "start_time": "2021-05-10T06:29:52.806721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our image embeddings shape is (3, 2048)\n",
      "Our image embeddings shape is (3, 1536)\n",
      "Our image embeddings shape is (3, 1792)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "image_embeddings0 = get_image_embeddings(image_paths,image_model_weight_sam)\n",
    "image_embeddings1 = get_image_embeddingsb3(image_paths,image_model_weight_path1)\n",
    "image_embeddings2 = get_image_embeddingsb4(image_paths,image_model_weight_path2)\n",
    "#image_embeddings3 = get_image_embeddings(image_paths,image_model_weight_path3)\n",
    "image_embeddings_list=[image_embeddings0,image_embeddings1,image_embeddings2]#,image_embeddings1,image_embeddings2]#[image_embeddings0,image_embeddings1,image_embeddings2,image_embeddings3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "structured-venice",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T06:30:25.241178Z",
     "iopub.status.busy": "2021-05-10T06:30:25.240306Z",
     "iopub.status.idle": "2021-05-10T06:30:25.244726Z",
     "shell.execute_reply": "2021-05-10T06:30:25.244313Z"
    },
    "papermill": {
     "duration": 0.034621,
     "end_time": "2021-05-10T06:30:25.244840",
     "exception": false,
     "start_time": "2021-05-10T06:30:25.210219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "#save=deepcopy(image_embeddings_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "southeast-ordinary",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T06:30:25.302484Z",
     "iopub.status.busy": "2021-05-10T06:30:25.301078Z",
     "iopub.status.idle": "2021-05-10T06:30:48.038470Z",
     "shell.execute_reply": "2021-05-10T06:30:48.038000Z"
    },
    "papermill": {
     "duration": 22.76745,
     "end_time": "2021-05-10T06:30:48.038640",
     "exception": false,
     "start_time": "2021-05-10T06:30:25.271190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertModel.\n",
      "\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at ../input/base-bert-model/base_bert.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our text embeddings shape is (3, 768)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11370"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#image_model_weight_path0\n",
    "#model = RobertaArcFace()\n",
    "text_embeddings = get_text_embeddings(text_model_weight_path0)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "comparative-being",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T06:30:48.100046Z",
     "iopub.status.busy": "2021-05-10T06:30:48.098366Z",
     "iopub.status.idle": "2021-05-10T06:30:48.100664Z",
     "shell.execute_reply": "2021-05-10T06:30:48.101053Z"
    },
    "papermill": {
     "duration": 0.034269,
     "end_time": "2021-05-10T06:30:48.101176",
     "exception": false,
     "start_time": "2021-05-10T06:30:48.066907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#image_text_embeddings=(image_embeddings+text_embeddings*0.4)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "junior-kansas",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T06:30:48.161147Z",
     "iopub.status.busy": "2021-05-10T06:30:48.160395Z",
     "iopub.status.idle": "2021-05-10T06:30:48.165152Z",
     "shell.execute_reply": "2021-05-10T06:30:48.164735Z"
    },
    "papermill": {
     "duration": 0.036251,
     "end_time": "2021-05-10T06:30:48.165248",
     "exception": false,
     "start_time": "2021-05-10T06:30:48.128997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "#print(text_embeddings2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "manufactured-doctrine",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T06:30:48.225637Z",
     "iopub.status.busy": "2021-05-10T06:30:48.225107Z",
     "iopub.status.idle": "2021-05-10T06:30:48.229075Z",
     "shell.execute_reply": "2021-05-10T06:30:48.228641Z"
    },
    "papermill": {
     "duration": 0.036083,
     "end_time": "2021-05-10T06:30:48.229178",
     "exception": false,
     "start_time": "2021-05-10T06:30:48.193095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def range_sigmoid(x,range):\n",
    "    #if  x<0:\n",
    "    #    return 0\n",
    "    p=np.log(3)*4/range#return 0.75 when x=range/4 \n",
    "    y=p*x\n",
    "    return np.exp(y)/(1+np.exp(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "electrical-grass",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T06:30:48.295915Z",
     "iopub.status.busy": "2021-05-10T06:30:48.295142Z",
     "iopub.status.idle": "2021-05-10T06:30:48.299160Z",
     "shell.execute_reply": "2021-05-10T06:30:48.298740Z"
    },
    "papermill": {
     "duration": 0.040266,
     "end_time": "2021-05-10T06:30:48.299262",
     "exception": false,
     "start_time": "2021-05-10T06:30:48.258996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_text_predictions(df, max_features = 25_000):\n",
    "    \n",
    "    model = TfidfVectorizer(stop_words = 'english', binary = True, max_features = max_features)\n",
    "    text_embeddings = model.fit_transform(df_cu['title']).toarray()\n",
    "    preds = []\n",
    "    CHUNK = 1024*4\n",
    "\n",
    "    print('Finding similar titles...')\n",
    "    CTS = len(df)//CHUNK\n",
    "    if len(df)%CHUNK!=0: CTS += 1\n",
    "    for j in range( CTS ):\n",
    "\n",
    "        a = j*CHUNK\n",
    "        b = (j+1)*CHUNK\n",
    "        b = min(b,len(df))\n",
    "        print('chunk',a,'to',b)\n",
    "\n",
    "        # COSINE SIMILARITY DISTANCE\n",
    "        cts = cupy.matmul( text_embeddings, text_embeddings[a:b].T).T\n",
    "\n",
    "        for k in range(b-a):\n",
    "            IDX = cupy.where(cts[k,]>0.75)[0]\n",
    "            o = df.iloc[cupy.asnumpy(IDX)].posting_id.values\n",
    "            preds.append(o)\n",
    "    \n",
    "    del model,text_embeddings\n",
    "    gc.collect()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "social-voluntary",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T06:30:48.371980Z",
     "iopub.status.busy": "2021-05-10T06:30:48.371251Z",
     "iopub.status.idle": "2021-05-10T06:30:48.374620Z",
     "shell.execute_reply": "2021-05-10T06:30:48.375048Z"
    },
    "papermill": {
     "duration": 0.047577,
     "end_time": "2021-05-10T06:30:48.375203",
     "exception": false,
     "start_time": "2021-05-10T06:30:48.327626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix\n",
    "def query_expansion( embeddings, KNN = 3,image = True):\n",
    "    model = NearestNeighbors(n_neighbors = KNN)\n",
    "    model.fit(embeddings)\n",
    "    distances, indices = model.kneighbors(embeddings)\n",
    "    res=deepcopy(embeddings)\n",
    "    #res.reshape(res.shape[0],1,res.shape[1])\n",
    "    matrix_length=embeddings.shape[0]\n",
    "    for i in range(matrix_length):\n",
    "        res[i]+=sum(embeddings[indices[i]])\n",
    "    res/=(KNN+1)\n",
    "    return res\n",
    "def get_neighbors(df, embeddings,best_thresholds, KNN = 50, image = True,test=False):\n",
    "    model = NearestNeighbors(n_neighbors = KNN)\n",
    "    model.fit(embeddings)\n",
    "    distances, indices = model.kneighbors(embeddings)\n",
    "    #print(distances.shape)\n",
    "    #best_thresholds_image=4.5\n",
    "    #best_thresholds_text=7.5\n",
    "    matrix_length=embeddings.shape[0]\n",
    "    predictions_score=lil_matrix((matrix_length,matrix_length))#np.zeros((embeddings.shape[0],embeddings.shape[0]))\n",
    "    # Iterate through different thresholds to maximize cv, run this in interactive mode, then replace else clause with a solid threshold\n",
    "    if test:#GET_CV:\n",
    "        if image:\n",
    "            thresholds = list(np.arange(2.6,3.4, 0.2))\n",
    "        else:\n",
    "            thresholds = list(np.arange(5, 15, 1))\n",
    "        scores = []\n",
    "        for threshold in thresholds:\n",
    "            predictions = []\n",
    "            for k in range(embeddings.shape[0]):\n",
    "                idx = np.where(distances[k,] < threshold)[0]\n",
    "                #predictions_score[k]+=\n",
    "                ids = indices[k,idx]\n",
    "                posting_ids = ' '.join(df['posting_id'].iloc[ids].values)\n",
    "                predictions.append(posting_ids)\n",
    "            df['pred_matches'] = predictions\n",
    "            df['f1'] = f1_score(df['matches'], df['pred_matches'])\n",
    "            score = df['f1'].mean()\n",
    "            print(f'Our f1 score for threshold {threshold} is {score}')\n",
    "            scores.append(score)\n",
    "        thresholds_scores = pd.DataFrame({'thresholds': thresholds, 'scores': scores})\n",
    "        max_score = thresholds_scores[thresholds_scores['scores'] == thresholds_scores['scores'].max()]\n",
    "        best_threshold = max_score['thresholds'].values[0]\n",
    "        best_score = max_score['scores'].values[0]\n",
    "        print(f'Our best score is {best_score} and has a threshold {best_threshold}')\n",
    "        \n",
    "        # Use threshold\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        for k in tqdm(range(embeddings.shape[0])):\n",
    "            if image:\n",
    "                best_thresholds=best_thresholds_image\n",
    "            else:\n",
    "                best_thresholds=best_thresholds_text\n",
    "            idx = np.where(distances[k,] < best_thresholds)[0]\n",
    "            #for i in idx:\n",
    "            #predictions_score[k,idx]+= np.frompyfunc(range_sigmoid,distances[k,idx]-best_thresholds,best_thresholds)\n",
    "            for i in idx:\n",
    "                predictions_score[k,i]=range_sigmoid(best_thresholds-distances[k,i],best_thresholds)\n",
    "            ids = indices[k,idx]\n",
    "            posting_ids = df['posting_id'].iloc[ids].values\n",
    "            predictions.append(posting_ids)\n",
    "        \"\"\"\n",
    "        return predictions_score\n",
    "    \n",
    "    # Because we are predicting the test set that have 70K images and different label groups, confidence should be smaller\n",
    "    else:\n",
    "        res_len=0\n",
    "        predictions = []\n",
    "        for k in tqdm(range(embeddings.shape[0])):\n",
    "            #if image:\n",
    "            #    best_thresholds=best_thresholds_image\n",
    "            #else:\n",
    "            #    best_thresholds=best_thresholds_text\n",
    "            idx = np.where(distances[k,] < best_thresholds*1.25)[0]\n",
    "            res_len+=len(idx)\n",
    "            #ids = indices[k,idx]\n",
    "            #predictions_score[k,idx]= np.frompyfunc(range_sigmoid,distances[k,idx]-best_thresholds,best_thresholds)\n",
    "            for i in idx:\n",
    "                predictions_score[k,indices[k,i]]=range_sigmoid(best_thresholds-distances[k,i],best_thresholds)\n",
    "            #ids = indices[k,idx]\n",
    "            #posting_ids = df['posting_id'].iloc[ids].values\n",
    "            #predictions.append(posting_ids)\n",
    "        #same_idx=np.where(prefictions_score > 0.5)[0]\n",
    "        #posting_ids = df['posting_id'].iloc[indices[k,same_idx]].values\n",
    "        print(res_len)\n",
    "    del model, distances, indices\n",
    "    gc.collect()\n",
    "    return df, predictions_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "combined-planet",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T06:30:48.436785Z",
     "iopub.status.busy": "2021-05-10T06:30:48.436069Z",
     "iopub.status.idle": "2021-05-10T06:30:48.438961Z",
     "shell.execute_reply": "2021-05-10T06:30:48.438545Z"
    },
    "papermill": {
     "duration": 0.035125,
     "end_time": "2021-05-10T06:30:48.439082",
     "exception": false,
     "start_time": "2021-05-10T06:30:48.403957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#image_embeddings_list=save.deepcopy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "august-agency",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T06:30:48.502294Z",
     "iopub.status.busy": "2021-05-10T06:30:48.501531Z",
     "iopub.status.idle": "2021-05-10T06:30:49.720320Z",
     "shell.execute_reply": "2021-05-10T06:30:49.719877Z"
    },
    "papermill": {
     "duration": 1.253051,
     "end_time": "2021-05-10T06:30:49.720509",
     "exception": false,
     "start_time": "2021-05-10T06:30:48.467458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_neighbors must be <= number of samples in index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-e3bca91ad198>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_embeddings_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mexpanded_em\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_expansion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mem\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mKNN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_em\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mth_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKNN\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mimage_scores_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#df, image_scores = get_neighbors(df, image_text_embeddings,4.5, KNN =50, image = True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-f39fae36df05>\u001b[0m in \u001b[0;36mget_neighbors\u001b[0;34m(df, embeddings, best_thresholds, KNN, image, test)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNearestNeighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;31m#print(distances.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m#best_thresholds_image=4.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mcuml/neighbors/nearest_neighbors.pyx\u001b[0m in \u001b[0;36mcuml.neighbors.nearest_neighbors.NearestNeighbors.kneighbors\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mcuml/neighbors/nearest_neighbors.pyx\u001b[0m in \u001b[0;36mcuml.neighbors.nearest_neighbors.NearestNeighbors._kneighbors\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: n_neighbors must be <= number of samples in index"
     ]
    }
   ],
   "source": [
    "# Get neighbors for image_embeddings\n",
    "\n",
    "image_scores_list=[]\n",
    "th_list=[0.6,1.8,3]\n",
    "#th_list=[0.8,2.1,4]\n",
    "for i, em in enumerate(image_embeddings_list):\n",
    "    expanded_em=query_expansion(em,KNN=2)\n",
    "    df, image_scores = get_neighbors(df, expanded_em,th_list[i], KNN =100, image = True)\n",
    "    image_scores_list.append(image_scores)\n",
    "#df, image_scores = get_neighbors(df, image_text_embeddings,4.5, KNN =50, image = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "unknown-custom",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T06:30:49.782905Z",
     "iopub.status.busy": "2021-05-10T06:30:49.782250Z",
     "iopub.status.idle": "2021-05-10T06:30:49.784793Z",
     "shell.execute_reply": "2021-05-10T06:30:49.785171Z"
    },
    "papermill": {
     "duration": 0.035379,
     "end_time": "2021-05-10T06:30:49.785302",
     "exception": false,
     "start_time": "2021-05-10T06:30:49.749923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get neighbors for image_embeddings\n",
    "#image_scores_list=[]\n",
    "#th_list=[0.9,2.4,4.6]\n",
    "#i=1\n",
    "#df, image_scores = get_neighbors(df, image_embeddings_list[i],th_list[i], KNN =100, image = True,test=True)\n",
    "#image_scores_list.append(image_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-cocktail",
   "metadata": {
    "papermill": {
     "duration": 0.029367,
     "end_time": "2021-05-10T06:30:49.852604",
     "exception": false,
     "start_time": "2021-05-10T06:30:49.823237",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "architectural-seattle",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T06:30:49.916725Z",
     "iopub.status.busy": "2021-05-10T06:30:49.915813Z",
     "iopub.status.idle": "2021-05-10T06:30:50.129020Z",
     "shell.execute_reply": "2021-05-10T06:30:50.128474Z"
    },
    "papermill": {
     "duration": 0.247251,
     "end_time": "2021-05-10T06:30:50.129144",
     "exception": false,
     "start_time": "2021-05-10T06:30:49.881893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_neighbors must be <= number of samples in index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-cbd767996a60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mth_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;31m#10.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mexpanded_em\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_expansion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mKNN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_em\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mth_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-f39fae36df05>\u001b[0m in \u001b[0;36mget_neighbors\u001b[0;34m(df, embeddings, best_thresholds, KNN, image, test)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNearestNeighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;31m#print(distances.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m#best_thresholds_image=4.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mcuml/neighbors/nearest_neighbors.pyx\u001b[0m in \u001b[0;36mcuml.neighbors.nearest_neighbors.NearestNeighbors.kneighbors\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mcuml/neighbors/nearest_neighbors.pyx\u001b[0m in \u001b[0;36mcuml.neighbors.nearest_neighbors.NearestNeighbors._kneighbors\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: n_neighbors must be <= number of samples in index"
     ]
    }
   ],
   "source": [
    "# Get neighbors for text_embeddings\n",
    "th_text=7#10.5\n",
    "expanded_em=query_expansion(text_embeddings,KNN=2)\n",
    "df,text_scores = get_neighbors(df, expanded_em,th_text, KNN = 100, image = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "primary-community",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T06:30:50.194337Z",
     "iopub.status.busy": "2021-05-10T06:30:50.193617Z",
     "iopub.status.idle": "2021-05-10T06:30:50.196731Z",
     "shell.execute_reply": "2021-05-10T06:30:50.196296Z"
    },
    "papermill": {
     "duration": 0.036697,
     "end_time": "2021-05-10T06:30:50.196849",
     "exception": false,
     "start_time": "2021-05-10T06:30:50.160152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df,text_scores2 = get_neighbors(df,text_embeddings2,1, KNN = 100, image = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "signal-homeless",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T06:30:50.262547Z",
     "iopub.status.busy": "2021-05-10T06:30:50.261800Z",
     "iopub.status.idle": "2021-05-10T06:30:50.264658Z",
     "shell.execute_reply": "2021-05-10T06:30:50.264227Z"
    },
    "papermill": {
     "duration": 0.037736,
     "end_time": "2021-05-10T06:30:50.264773",
     "exception": false,
     "start_time": "2021-05-10T06:30:50.227037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tostring_predictions(x):\n",
    "    return ' '.join( np.unique(x) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faced-segment",
   "metadata": {
    "papermill": {
     "duration": 0.029645,
     "end_time": "2021-05-10T06:30:50.325858",
     "exception": false,
     "start_time": "2021-05-10T06:30:50.296213",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "protected-agency",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T06:30:50.390201Z",
     "iopub.status.busy": "2021-05-10T06:30:50.389383Z",
     "iopub.status.idle": "2021-05-10T06:30:50.392272Z",
     "shell.execute_reply": "2021-05-10T06:30:50.391842Z"
    },
    "papermill": {
     "duration": 0.036179,
     "end_time": "2021-05-10T06:30:50.392376",
     "exception": false,
     "start_time": "2021-05-10T06:30:50.356197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(image_scores.getrow(1).nonzero())\n",
    "#print(image_scores.getrow(1).toarray())\n",
    "#print(np.where(image_scores.getrow(1).toarray() >0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "spatial-logistics",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T06:30:50.478767Z",
     "iopub.status.busy": "2021-05-10T06:30:50.477914Z",
     "iopub.status.idle": "2021-05-10T06:30:50.482056Z",
     "shell.execute_reply": "2021-05-10T06:30:50.481518Z"
    },
    "papermill": {
     "duration": 0.059636,
     "end_time": "2021-05-10T06:30:50.482168",
     "exception": false,
     "start_time": "2021-05-10T06:30:50.422532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-cf079445e5df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres_scores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#res_scores+=image_scores.tocsr()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.35\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.325\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.325\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mres_scores\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mimage_scores_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text_scores' is not defined"
     ]
    }
   ],
   "source": [
    "res_scores=text_scores.tocsr()\n",
    "#res_scores+=image_scores.tocsr()\n",
    "weights=[0.35,0.325,0.325]\n",
    "for i in range(3):\n",
    "    res_scores+=image_scores_list[i].tocsr()*weights[i]\n",
    "res_scores/=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "rough-knitting",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T06:30:50.547508Z",
     "iopub.status.busy": "2021-05-10T06:30:50.546856Z",
     "iopub.status.idle": "2021-05-10T06:30:50.549761Z",
     "shell.execute_reply": "2021-05-10T06:30:50.549228Z"
    },
    "papermill": {
     "duration": 0.036809,
     "end_time": "2021-05-10T06:30:50.549871",
     "exception": false,
     "start_time": "2021-05-10T06:30:50.513062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#res_scores=image_scores_list[0].tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "environmental-waters",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T06:30:50.638049Z",
     "iopub.status.busy": "2021-05-10T06:30:50.637231Z",
     "iopub.status.idle": "2021-05-10T06:30:50.641208Z",
     "shell.execute_reply": "2021-05-10T06:30:50.640684Z"
    },
    "papermill": {
     "duration": 0.060506,
     "end_time": "2021-05-10T06:30:50.641323",
     "exception": false,
     "start_time": "2021-05-10T06:30:50.580817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-15f00cb81fbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#    res_scores+=image_scores.tocsr()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#1+len(image_scores_list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0marr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.35\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'res_scores' is not defined"
     ]
    }
   ],
   "source": [
    "res_predictions = []\n",
    "#res_scores+=image_scores_list[2].tocsr()*0.33\n",
    "#for image_scores in image_scores_list:\n",
    "#    res_scores+=image_scores.tocsr()\n",
    "#1+len(image_scores_list)\n",
    "for i in range(res_scores.shape[0]):\n",
    "    arr=res_scores.getrow(i).toarray()\n",
    "    idx=np.where(arr>0.35)[1]\n",
    "    posting_ids = df['posting_id'].iloc[idx].values\n",
    "    res_predictions.append(tostring_predictions(posting_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "behavioral-judges",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T06:30:50.707710Z",
     "iopub.status.busy": "2021-05-10T06:30:50.707034Z",
     "iopub.status.idle": "2021-05-10T06:30:50.710013Z",
     "shell.execute_reply": "2021-05-10T06:30:50.709601Z"
    },
    "papermill": {
     "duration": 0.037585,
     "end_time": "2021-05-10T06:30:50.710125",
     "exception": false,
     "start_time": "2021-05-10T06:30:50.672540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(res_scores.getrow(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "transparent-major",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-05-10T06:30:50.798942Z",
     "iopub.status.busy": "2021-05-10T06:30:50.795343Z",
     "iopub.status.idle": "2021-05-10T06:30:50.816011Z",
     "shell.execute_reply": "2021-05-10T06:30:50.815493Z"
    },
    "papermill": {
     "duration": 0.074406,
     "end_time": "2021-05-10T06:30:50.816174",
     "exception": false,
     "start_time": "2021-05-10T06:30:50.741768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (0) does not match length of index (3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-88277412a52c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#df['image_predictions'] = image_predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#df['text_predictions'] = text_predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'matches'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mres_predictions\u001b[0m\u001b[0;31m##df.apply(combine_predictions, axis = 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'posting_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'matches'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'submission.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3042\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3043\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3046\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3118\u001b[0m         \"\"\"\n\u001b[1;32m   3119\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3120\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3121\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   3766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3767\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3768\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3769\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3770\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         raise ValueError(\n\u001b[0;32m--> 748\u001b[0;31m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0;34m\"does not match length of index \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (0) does not match length of index (3)"
     ]
    }
   ],
   "source": [
    "# Concatenate image predctions with text predictions\n",
    "\n",
    "if GET_CV:\n",
    "    #df['image_predictions'] = image_predictions\n",
    "    #df['text_predictions'] = text_predictions\n",
    "    df['pred_matches'] = res_predictions\n",
    "    df['f1'] = f1_score(df['matches'], df['pred_matches'])\n",
    "    score = df['f1'].mean()\n",
    "    print(f'Our final f1 cv score is {score}')\n",
    "    #df['matches'] = df['pred_matches']\n",
    "    df[['posting_id', 'pred_matches']].to_csv('submission.csv', index = False)\n",
    "else:\n",
    "    #df['image_predictions'] = image_predictions\n",
    "    #df['text_predictions'] = text_predictions\n",
    "    df['matches'] =  res_predictions##df.apply(combine_predictions, axis = 1)\n",
    "    df[['posting_id', 'matches']].to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "atlantic-stock",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T06:30:50.888438Z",
     "iopub.status.busy": "2021-05-10T06:30:50.887850Z",
     "iopub.status.idle": "2021-05-10T06:30:50.896188Z",
     "shell.execute_reply": "2021-05-10T06:30:50.895699Z"
    },
    "papermill": {
     "duration": 0.047854,
     "end_time": "2021-05-10T06:30:50.896321",
     "exception": false,
     "start_time": "2021-05-10T06:30:50.848467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_2255846744</td>\n",
       "      <td>0006c8e5462ae52167402bac1c2e916e.jpg</td>\n",
       "      <td>ecc292392dc7687a</td>\n",
       "      <td>Edufuntoys - CHARACTER PHONE ada lampu dan mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_3588702337</td>\n",
       "      <td>0007585c4d0f932859339129f709bfdc.jpg</td>\n",
       "      <td>e9968f60d2699e2c</td>\n",
       "      <td>(Beli 1 Free Spatula) Masker Komedo | Blackhea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_4015706929</td>\n",
       "      <td>0008377d3662e83ef44e1881af38b879.jpg</td>\n",
       "      <td>ba81c17e3581cabe</td>\n",
       "      <td>READY Lemonilo Mie instant sehat kuah dan goreng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        posting_id                                 image       image_phash  \\\n",
       "0  test_2255846744  0006c8e5462ae52167402bac1c2e916e.jpg  ecc292392dc7687a   \n",
       "1  test_3588702337  0007585c4d0f932859339129f709bfdc.jpg  e9968f60d2699e2c   \n",
       "2  test_4015706929  0008377d3662e83ef44e1881af38b879.jpg  ba81c17e3581cabe   \n",
       "\n",
       "                                               title  \n",
       "0  Edufuntoys - CHARACTER PHONE ada lampu dan mus...  \n",
       "1  (Beli 1 Free Spatula) Masker Komedo | Blackhea...  \n",
       "2   READY Lemonilo Mie instant sehat kuah dan goreng  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-roller",
   "metadata": {
    "papermill": {
     "duration": 0.032179,
     "end_time": "2021-05-10T06:30:50.960816",
     "exception": false,
     "start_time": "2021-05-10T06:30:50.928637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-techno",
   "metadata": {
    "papermill": {
     "duration": 0.032435,
     "end_time": "2021-05-10T06:30:51.025537",
     "exception": false,
     "start_time": "2021-05-10T06:30:50.993102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-dollar",
   "metadata": {
    "papermill": {
     "duration": 0.032233,
     "end_time": "2021-05-10T06:30:51.090466",
     "exception": false,
     "start_time": "2021-05-10T06:30:51.058233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 141.796263,
   "end_time": "2021-05-10T06:30:54.258598",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-10T06:28:32.462335",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
