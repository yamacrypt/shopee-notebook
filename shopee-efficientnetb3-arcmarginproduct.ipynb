{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q efficientnet\n!pip install tensorflow_addons\nimport re\nimport os\nimport numpy as np\nimport pandas as pd\nimport random\nimport tensorflow as tf\nimport efficientnet.tfkeras as efn\nfrom sklearn import metrics\nfrom sklearn.model_selection import KFold, train_test_split\nfrom tensorflow.keras import backend as K\nimport tensorflow_addons as tfa\nfrom tqdm.notebook import tqdm\n\nfrom kaggle_datasets import KaggleDatasets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!git clone https://github.com/hoangthang1607/nfnets-Tensorflow-2\n#!touch ./nfnets-Tensorflow-2/__init__.py    \n#!mv nfnets-Tensorflow-2 tfnfnet","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!cp ../input/nfnet-base/tfnfnet ./tfnfnet -r","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/Jannoshh/simple-sam\n!mv simple-sam sam\nimport sam\nimport sam.sam\nfrom sam.sam import sam_train_step","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom kaggle_datasets import KaggleDatasets\nGCS_PATH = KaggleDatasets().get_gcs_path('shopee-product-matching')\ndf = pd.read_csv(GCS_PATH+'/train.csv',usecols=[4])\ns=set()\nres=df.values\nfor ele in res:\n    s.add(ele[0])\nprint(len(s))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n    # set: this is always the case on Kaggle.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.TPUStrategy(tpu)\nelse:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For tf.dataset\nAUTO = tf.data.experimental.AUTOTUNE\n\n# Data access\nGCS_PATH = KaggleDatasets().get_gcs_path('shopee-tfrecord-512x512')\n\n# Configuration\nEPOCHS = 20\nBATCH_SIZE = 32 * strategy.num_replicas_in_sync\nAUG_BATCH=BATCH_SIZE\nIMAGE_SIZE = [512, 512]\n# Seed\nSEED = 42\n# Learning rate\nLR = 0.001\n# Verbosity\nVERBOSE = 2\n# Number of classes\nN_CLASSES = len(s)\n# Number of folds\nFOLDS = 5\n\n# Training filenames directory\nTRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/*.tfrec')\n# Test filenames directory\nTEST_FILENAMES = tf.io.gfile.glob(KaggleDatasets().get_gcs_path('shopee-product-matching')+'/test_images/*.jpg')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MIXED_PRECISION = False\nXLA_ACCELERATE = False\nif MIXED_PRECISION:\n    from tensorflow.keras.mixed_precision import experimental as mixed_precision\n    if tpu: policy = tf.keras.mixed_precision.experimental.Policy('mixed_bfloat16')\n    else: policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n    mixed_precision.set_policy(policy)\n    print('Mixed precision enabled')\n\nif XLA_ACCELERATE:\n    tf.config.optimizer.set_jit(True)\n    print('Accelerated Linear Algebra enabled')\ndef resizemix(image,label,PROBABLITY = 1.0):\n    DIM = IMAGE_SIZE[0]\n    #CLASSES = 104\n    classes=N_CLASSES\n    imgs = []; labs = []\n    for j in range(AUG_BATCH):\n        # DO CUTMIX WITH PROBABILITY DEFINED ABOVE\n        P = tf.cast( tf.random.uniform([],0,1)<=PROBABILITY, tf.int32)\n        # CHOOSE RANDOM IMAGE TO CUTMIX WITH\n        k = tf.cast( tf.random.uniform([],0,AUG_BATCH),tf.int32)\n        # CHOOSE RANDOM LOCATION\n        x = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n        y = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n        b = tf.random.uniform([],0,1) # this is beta dist with alpha=1.0\n        WIDTH = tf.cast( DIM * tf.math.sqrt(1-b),tf.int32) * P\n        ya = tf.math.maximum(0,y-WIDTH//2)\n        yb = tf.math.minimum(DIM,y+WIDTH//2)\n        xa = tf.math.maximum(0,x-WIDTH//2)\n        xb = tf.math.minimum(DIM,x+WIDTH//2)\n        # MAKE CUTMIX IMAGE\n        one = image[j,ya:yb,0:xa,:]\n        two = image[k,ya:yb,xa:xb,:]\n        three = image[j,ya:yb,xb:DIM,:]\n        middle = tf.concat([one,two,three],axis=1)\n        img = tf.concat([image[j,0:ya,:,:],middle,image[j,yb:DIM,:,:]],axis=0)\n        imgs.append(img)\n        # MAKE CUTMIX LABEL\n        a = tf.cast(WIDTH*WIDTH/DIM/DIM,tf.float32)\n        if len(label.shape)==1:\n            lab1 = tf.one_hot(label[j],classes)\n            lab2 = tf.one_hot(label[k],classes)\n        else:\n            lab1 = label[j,]\n            lab2 = label[k,]\n        labs.append((1-a)*lab1 + a*lab2)\n            \n    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n    image2 = tf.reshape(tf.stack(imgs),(AUG_BATCH,DIM,DIM,3))\n    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,classes))\n    return image2,label2\ndef cutmix(image, label, PROBABILITY = 1.0):\n    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\n    # output - a batch of images with cutmix applied\n    DIM = IMAGE_SIZE[0]\n    #CLASSES = 104\n    classes=N_CLASSES\n    imgs = []; labs = []\n    for j in range(AUG_BATCH):\n        # DO CUTMIX WITH PROBABILITY DEFINED ABOVE\n        P = tf.cast( tf.random.uniform([],0,1)<=PROBABILITY, tf.int32)\n        # CHOOSE RANDOM IMAGE TO CUTMIX WITH\n        k = tf.cast( tf.random.uniform([],0,AUG_BATCH),tf.int32)\n        # CHOOSE RANDOM LOCATION\n        x = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n        y = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n        b = tf.random.uniform([],0,1) # this is beta dist with alpha=1.0\n        WIDTH = tf.cast( DIM * tf.math.sqrt(1-b),tf.int32) * P\n        ya = tf.math.maximum(0,y-WIDTH//2)\n        yb = tf.math.minimum(DIM,y+WIDTH//2)\n        xa = tf.math.maximum(0,x-WIDTH//2)\n        xb = tf.math.minimum(DIM,x+WIDTH//2)\n        # MAKE CUTMIX IMAGE\n        one = image[j,ya:yb,0:xa,:]\n        two = image[k,ya:yb,xa:xb,:]\n        three = image[j,ya:yb,xb:DIM,:]\n        middle = tf.concat([one,two,three],axis=1)\n        img = tf.concat([image[j,0:ya,:,:],middle,image[j,yb:DIM,:,:]],axis=0)\n        imgs.append(img)\n        # MAKE CUTMIX LABEL\n        a = tf.cast(WIDTH*WIDTH/DIM/DIM,tf.float32)\n        if len(label.shape)==1:\n            lab1 = tf.one_hot(label[j],classes)\n            lab2 = tf.one_hot(label[k],classes)\n        else:\n            lab1 = label[j,]\n            lab2 = label[k,]\n        labs.append((1-a)*lab1 + a*lab2)\n            \n    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n    image2 = tf.reshape(tf.stack(imgs),(AUG_BATCH,DIM,DIM,3))\n    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,classes))\n    return image2,label2\ndef mixup(image, label, PROBABILITY = 1.0):\n    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\n    # output - a batch of images with mixup applied\n    DIM = IMAGE_SIZE[0]\n    #CLASSES = 104\n    classes=N_CLASSES\n    imgs = []; labs = []\n    for j in range(AUG_BATCH):\n        # DO MIXUP WITH PROBABILITY DEFINED ABOVE\n        P = tf.cast( tf.random.uniform([],0,1)<=PROBABILITY, tf.float32)\n        # CHOOSE RANDOM\n        k = tf.cast( tf.random.uniform([],0,AUG_BATCH),tf.int32)\n        a = tf.random.uniform([],0,1)*P # this is beta dist with alpha=1.0\n        # MAKE MIXUP IMAGE\n        img1 = image[j,]\n        img2 = image[k,]\n        imgs.append((1-a)*img1 + a*img2)\n        # MAKE CUTMIX LABEL\n        if len(label.shape)==1:\n            lab1 = tf.one_hot(label[j], classes)\n            lab2 = tf.one_hot(label[k], classes)\n        else:\n            lab1 = label[j,]\n            lab2 = label[k,]\n        labs.append((1-a)*lab1 + a*lab2)\n            \n    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n    image2 = tf.reshape(tf.stack(imgs),(AUG_BATCH,DIM,DIM,3))\n    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH, classes))\n    return image2,label2\ndef mixup_transform(posting_id, image, label, matches):\n    # THIS FUNCTION APPLIES BOTH CUTMIX AND MIXUP\n    DIM = IMAGE_SIZE[0]\n    classes=N_CLASSES\n    #CLASSES = 104\n    SWITCH = 0.5\n    CUTMIX_PROB = 0.666\n    MIXUP_PROB = 0.666\n    # FOR SWITCH PERCENT OF TIME WE DO CUTMIX AND (1-SWITCH) WE DO MIXUP\n    image2, label2 = cutmix(image, label, CUTMIX_PROB)\n    image3, label3 = mixup(image, label, MIXUP_PROB)\n    imgs = []; labs = []\n    for j in range(AUG_BATCH):\n        P = tf.cast( tf.random.uniform([],0,1)<=SWITCH, tf.float32)\n        imgs.append(P*image2[j,]+(1-P)*image3[j,])\n        labs.append(P*label2[j,]+(1-P)*label3[j,])\n    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n    image4 = tf.reshape(tf.stack(imgs),(AUG_BATCH,DIM,DIM,3))\n    label4 = tf.reshape(tf.stack(labs),(AUG_BATCH,classes))\n    \n    return posting_id,image4,label4,matches","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to get our f1 score\n\ndef f1_score(y_true, y_pred):\n    y_true = y_true.apply(lambda x: set(x.split()))\n    y_pred = y_pred.apply(lambda x: set(x.split()))\n    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n    len_y_pred = y_pred.apply(lambda x: len(x)).values\n    len_y_true = y_true.apply(lambda x: len(x)).values\n    f1 = 2 * intersection / (len_y_pred + len_y_true)\n    return f1\n\n# Function to seed everything\ndef seed_everything(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    tf.random.set_seed(seed)\n    \ndef arcface_format(posting_id, image, label_group, matches):\n    return posting_id, {'inp1': image, 'inp2': label_group}, label_group, matches\ndef get_mat(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n    # returns 3x3 transformmatrix which transforms indicies\n        \n    # CONVERT DEGREES TO RADIANS\n    rotation = math.pi * rotation / 180.\n    shear = math.pi * shear / 180.\n    \n    # ROTATION MATRIX\n    c1 = tf.math.cos(rotation)\n    s1 = tf.math.sin(rotation)\n    one = tf.constant([1],dtype='float32')\n    zero = tf.constant([0],dtype='float32')\n    rotation_matrix = tf.reshape( tf.concat([c1,s1,zero, -s1,c1,zero, zero,zero,one],axis=0),[3,3] )\n        \n    # SHEAR MATRIX\n    c2 = tf.math.cos(shear)\n    s2 = tf.math.sin(shear)\n    shear_matrix = tf.reshape( tf.concat([one,s2,zero, zero,c2,zero, zero,zero,one],axis=0),[3,3] )    \n    \n    # ZOOM MATRIX\n    zoom_matrix = tf.reshape( tf.concat([one/height_zoom,zero,zero, zero,one/width_zoom,zero, zero,zero,one],axis=0),[3,3] )\n    \n    # SHIFT MATRIX\n    shift_matrix = tf.reshape( tf.concat([one,zero,height_shift, zero,one,width_shift, zero,zero,one],axis=0),[3,3] )\n    \n    return K.dot(K.dot(rotation_matrix, shear_matrix), K.dot(zoom_matrix, shift_matrix))\ndef transform(image,label):\n    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n    # output - image randomly rotated, sheared, zoomed, and shifted\n    DIM = IMAGE_SIZE[0]\n    XDIM = DIM%2 #fix for size 331\n    \n    rot = 60. * tf.random.normal([1],dtype='float32')\n    shr = 5. * tf.random.normal([1],dtype='float32') \n    h_zoom = 1.0 + tf.random.normal([1],dtype='float32')/10.\n    w_zoom = 1.0 + tf.random.normal([1],dtype='float32')/10.\n    h_shift = 16. * tf.random.normal([1],dtype='float32') \n    w_shift = 16. * tf.random.normal([1],dtype='float32') \n  \n    # GET TRANSFORMATION MATRIX\n    m = get_mat(rot,shr,h_zoom,w_zoom,h_shift,w_shift) \n\n    # LIST DESTINATION PIXEL INDICES\n    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n    z = tf.ones([DIM*DIM],dtype='int32')\n    idx = tf.stack( [x,y,z] )\n    \n    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n    idx2 = K.dot(m,tf.cast(idx,dtype='float32'))\n    idx2 = K.cast(idx2,dtype='int32')\n    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n    \n    # FIND ORIGIN PIXEL VALUES           \n    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n    d = tf.gather_nd(image,tf.transpose(idx3))\n    image=tf.reshape(d,[DIM,DIM,3])\n    p_spatial = tf.random.uniform([], 0, 1.0, dtype = tf.float32)\n    p_rotate = tf.random.uniform([], 0, 1.0, dtype = tf.float32)\n    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype = tf.float32)\n    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype = tf.float32)\n    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype = tf.float32)\n    p_crop = tf.random.uniform([], 0, 1.0, dtype = tf.float32)\n            \n    # Flips\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    if p_spatial > 0.75:\n        image = tf.image.transpose(image)\n        \n        \n    # Pixel-level transforms\n    if p_pixel_1 >= 0.4:\n        image = tf.image.random_saturation(image, lower = 0.7, upper = 1.3)\n    if p_pixel_2 >= 0.4:\n        image = tf.image.random_contrast(image, lower = 0.8, upper = 1.2)\n    if p_pixel_3 >= 0.4:\n        image = tf.image.random_brightness(image, max_delta = 0.1)\n    return image,label\n# Data augmentation function\ndef data_augment(posting_id, image, label_group, matches):\n    #image,label_group=transform(image,label_group)\n    \"\"\"image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    image = tf.image.random_hue(image, 0.01)\n    image = tf.image.random_saturation(image, 0.70, 1.30)\n    image = tf.image.random_contrast(image, 0.80, 1.20)\n    image = tf.image.random_brightness(image, 0.10)\"\"\"\n    image,label_group=transform(image,label_group)\n    return posting_id, image, label_group, matches\n\n# Function to decode our images\ndef decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels = 3)\n    image = tf.image.resize(image, IMAGE_SIZE)\n    image = tf.cast(image, tf.float32) / 255.0\n    return image\n\n# This function parse our images and also get the target variable\ndef read_labeled_tfrecord(example,onehot=False):\n    LABELED_TFREC_FORMAT = {\n        \"posting_id\": tf.io.FixedLenFeature([], tf.string),\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"label_group\": tf.io.FixedLenFeature([], tf.int64),\n        \"matches\": tf.io.FixedLenFeature([], tf.string)\n    }\n\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    posting_id = example['posting_id']\n    image = decode_image(example['image'])\n    if onehot:\n        label_group = tf.one_hot(tf.cast(example['label_group'], tf.int32), depth = N_CLASSES)\n    else:\n        label_group = tf.cast(example['label_group'], tf.int32)\n    matches = example['matches']\n    return posting_id, image, label_group, matches\nfrom functools import partial\n# This function loads TF Records and parse them into tensors\ndef load_dataset(filenames, ordered = False,_onehot=False):\n    \n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False \n        \n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads = AUTO)\n    dataset = dataset.with_options(ignore_order)\n    dataset = dataset.map(partial(read_labeled_tfrecord,onehot=_onehot), num_parallel_calls = AUTO) \n    return dataset\n\n# This function is to get our training tensors\ndef get_training_dataset(filenames, ordered = False,mixup=False):\n    dataset = load_dataset(filenames, ordered = ordered,_onehot=mixup)\n    dataset = dataset.map(data_augment, num_parallel_calls = AUTO)\n    if mixup==False:\n        dataset = dataset.map(arcface_format, num_parallel_calls = AUTO)\n    dataset = dataset.repeat()\n    if mixup: \n        dataset = dataset.batch(BATCH_SIZE)\n        dataset = dataset.map(mixup_transform, num_parallel_calls=AUTO)\n        dataset.unbatch()\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\n# This function is to get our validation tensors\ndef get_validation_dataset(filenames, ordered = True,mixup=False):\n    dataset = load_dataset(filenames, ordered = ordered,_onehot=mixup)\n    dataset = dataset.map(arcface_format, num_parallel_calls = AUTO)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) \n    return dataset\ndef get_test_dataset(filenames, ordered = True):\n    dataset = load_dataset(filenames, ordered = ordered)\n    dataset = dataset.map(arcface_format, num_parallel_calls = AUTO)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) \n    return dataset\n# Function to count how many photos we have in\ndef count_data_items(filenames):\n    # The number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)\n\nNUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\nprint(f'Dataset: {NUM_TRAINING_IMAGES} training images')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow_addons as tfa\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n# Function for a custom learning rate scheduler with warmup and decay\ndef get_lr_callback():\n    lr_start   = 0.000001\n    lr_max     = 0.000005 * BATCH_SIZE\n    lr_min     = 0.000001\n    lr_ramp_ep = 5\n    lr_sus_ep  = 0\n    lr_decay   = 0.8\n   \n    def lrfn(epoch):\n        if epoch < lr_ramp_ep:\n            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start   \n        elif epoch < lr_ramp_ep + lr_sus_ep:\n            lr = lr_max    \n        else:\n            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min    \n        return lr\n\n    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)\n    return lr_callback\n\n# Arcmarginproduct class keras layer\nclass ArcMarginProduct(tf.keras.layers.Layer):\n    '''\n    Implements large margin arc distance.\n\n    Reference:\n        https://arxiv.org/pdf/1801.07698.pdf\n        https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/\n            blob/master/src/modeling/metric_learning.py\n    '''\n    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n                 ls_eps=0.0, **kwargs):\n\n        super(ArcMarginProduct, self).__init__(**kwargs)\n\n        self.n_classes = n_classes\n        self.s = s\n        self.m = m\n        self.ls_eps = ls_eps\n        self.easy_margin = easy_margin\n        self.cos_m = tf.math.cos(m)\n        self.sin_m = tf.math.sin(m)\n        self.th = tf.math.cos(math.pi - m)\n        self.mm = tf.math.sin(math.pi - m) * m\n\n    def get_config(self):\n\n        config = super().get_config().copy()\n        config.update({\n            'n_classes': self.n_classes,\n            's': self.s,\n            'm': self.m,\n            'ls_eps': self.ls_eps,\n            'easy_margin': self.easy_margin,\n        })\n        return config\n\n    def build(self, input_shape):\n        super(ArcMarginProduct, self).build(input_shape[0])\n\n        self.W = self.add_weight(\n            name='W',\n            shape=(int(input_shape[0][-1]), self.n_classes),\n            initializer='glorot_uniform',\n            dtype='float32',\n            trainable=True,\n            regularizer=None)\n\n    def call(self, inputs):\n        X, y = inputs\n        y = tf.cast(y, dtype=tf.int32)\n        cosine = tf.matmul(\n            tf.math.l2_normalize(X, axis=1),\n            tf.math.l2_normalize(self.W, axis=0)\n        )\n        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n        phi = cosine * self.cos_m - sine * self.sin_m\n        if self.easy_margin:\n            phi = tf.where(cosine > 0, phi, cosine)\n        else:\n            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n        one_hot = tf.cast(\n            tf.one_hot(y, depth=self.n_classes),\n            dtype=cosine.dtype\n        )\n        if self.ls_eps > 0:\n            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n\n        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n        output *= self.s\n        return output\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from bayes_opt import BayesianOptimization\ndef buildModel(m):\n    model = get_model()\n    train_and_evaluate()\ndef bayesOpt():\n    pbounds = {\n        'mm':(0.1,0.9),\n        'ss':(5,20)\n    }\n    optimizer = BayesianOptimization(f=getModel, pbounds=pbounds)\n    optimizer.maximize(init_points=5, n_iter=10, acq='ucb')\n    return optimizer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/Jannoshh/simple-sam\n#!touch ./nfnets-Tensorflow-2/__init__.py    \n#!mv nfnets-Tensorflow-2 tfnfnet","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.layers import Layer\nfrom tensorflow.keras.initializers import Constant\nfrom tensorflow.python.keras.utils import tf_utils\n\n\ndef _resolve_training(layer, training):\n    if training is None:\n        training = K.learning_phase()\n    if isinstance(training, int):\n        training = bool(training)\n    if not layer.trainable:\n        # When the layer is not trainable, override the value\n        training = False\n    return training#tf_utils.constant_value(training)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow.keras.layers\nclass AdaCos(Layer):\n    \"\"\"\n    Implementation of AdaCos layer. Reference: https://arxiv.org/abs/1905.00292\n    \n    Arguments:\n      num_classes: number of classes to classify\n      is_dynamic: if False, use Fixed AdaCos. Else, use Dynamic Adacos.\n      regularizer: weights regularizer\n    \"\"\"\n    def __init__(self,\n                 num_classes,\n                 is_dynamic=True,\n                 regularizer=None,\n                 **kwargs):\n\n        super().__init__(**kwargs)\n        self._n_classes = num_classes\n        self._init_s = math.sqrt(2) * math.log(num_classes - 1)\n        self._is_dynamic = is_dynamic\n        self._regularizer = regularizer\n\n    def build(self, input_shape):\n        embedding_shape, label_shape = input_shape\n        self._w = self.add_weight(name='W',shape=(embedding_shape[-1], self._n_classes),\n                                  initializer='glorot_uniform',\n                                  trainable=True,\n                                  regularizer=self._regularizer)\n        if self._is_dynamic:\n            self._s = self.add_weight(name='S',shape=(),\n                                      initializer=Constant(self._init_s),\n                                      trainable=False,\n                                      aggregation=tf.VariableAggregation.MEAN)\n\n    def call(self, inputs, training=None):\n        embedding, label = inputs\n        label = tf.cast(label, dtype=tf.int32)\n\n        # Squeezing is necessary for Keras. It expands the dimension to (n, 1)\n        label = tf.reshape(label, [-1])\n\n        # Normalize features and weights and compute dot product\n        x = tf.nn.l2_normalize(embedding, axis=1)\n        w = tf.nn.l2_normalize(self._w, axis=0)\n        logits = tf.matmul(x, w)\n\n        # Fixed AdaCos\n        is_dynamic = self._is_dynamic#tf_utils.constant_value(self._is_dynamic)\n        if not is_dynamic:\n            # _s is not created since we are not in dynamic mode\n            output = tf.multiply(self._init_s, logits)\n            return output\n\n        training = _resolve_training(self, training)\n        if not training:\n            # We don't have labels to update _s if we're not in training mode\n            return self._s * logits\n        else:\n            theta = tf.math.acos(\n                    K.clip(logits, -1.0 + K.epsilon(), 1.0 - K.epsilon()))\n            one_hot = tf.one_hot(label, depth=self._n_classes)\n            b_avg = tf.where(one_hot < 1.0,\n                             tf.exp(self._s * logits),\n                             tf.zeros_like(logits))\n            b_avg = tf.reduce_mean(tf.reduce_sum(b_avg, axis=1))\n            theta_class = tf.gather_nd(\n                    theta,\n                    tf.stack([\n                        tf.range(tf.shape(label)[0]),\n                        tf.cast(label, tf.int32)\n                    ], axis=1))\n            mid_index = tf.shape(theta_class)[0] // 2 + 1\n            theta_med = tf.nn.top_k(theta_class, mid_index).values[-1]\n\n            # Since _s is not trainable, this assignment is safe. Also,\n            # tf.function ensures that this will run in the right order.\n            self._s.assign(\n                    tf.math.log(b_avg) /\n                    tf.math.cos(tf.minimum(math.pi/4, theta_med)))\n\n            # Return scaled logits\n            return self._s * logits","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ArcFace(Layer):\n    \"\"\"\n    Implementation of ArcFace layer. Reference: https://arxiv.org/abs/1801.07698\n    \n    Arguments:\n      num_classes: number of classes to classify\n      s: scale factor\n      m: margin\n      regularizer: weights regularizer\n    \"\"\"\n    def __init__(self,\n                 num_classes,\n                 s=30.0,\n                 m=0.5,\n                 regularizer=None,\n                 name='arcface',\n                 **kwargs):\n        \n        super().__init__(name=name, **kwargs)\n        self._n_classes = num_classes\n        self._s = float(s)\n        self._m = float(m)\n        self._regularizer = regularizer\n\n    def build(self, input_shape):\n        embedding_shape, label_shape = input_shape\n        self._w = self.add_weight(shape=(embedding_shape[-1], self._n_classes),\n                                  initializer='glorot_uniform',\n                                  trainable=True,\n                                  regularizer=self._regularizer,\n                                  name='cosine_weights')\n\n    def call(self, inputs, training=None):\n        \"\"\"\n        During training, requires 2 inputs: embedding (after backbone+pool+dense),\n        and ground truth labels. The labels should be sparse (and use\n        sparse_categorical_crossentropy as loss).\n        \"\"\"\n        embedding, label = inputs\n\n        # Squeezing is necessary for Keras. It expands the dimension to (n, 1)\n        label = tf.reshape(label, [-1], name='label_shape_correction')\n\n        # Normalize features and weights and compute dot product\n        x = tf.nn.l2_normalize(embedding, axis=1, name='normalize_prelogits')\n        w = tf.nn.l2_normalize(self._w, axis=0, name='normalize_weights')\n        cosine_sim = tf.matmul(x, w, name='cosine_similarity')\n\n        training = resolve_training_flag(self, training)\n        if not training:\n            # We don't have labels if we're not in training mode\n            return self._s * cosine_sim\n        else:\n            one_hot_labels = tf.one_hot(label,\n                                        depth=self._n_classes,\n                                        name='one_hot_labels')\n            theta = tf.math.acos(K.clip(\n                    cosine_sim, -1.0 + K.epsilon(), 1.0 - K.epsilon()))\n            selected_labels = tf.where(tf.greater(theta, math.pi - self._m),\n                                       tf.zeros_like(one_hot_labels),\n                                       one_hot_labels,\n                                       name='selected_labels')\n            final_theta = tf.where(tf.cast(selected_labels, dtype=tf.bool),\n                                   theta + self._m,\n                                   theta,\n                                   name='final_theta')\n            output = tf.math.cos(final_theta, name='cosine_sim_with_margin')\n            return self._s * output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip uninstall -y nfnets-keras\n!pip install -U git+https://github.com/yamacrypt/nfnets-keras\nimport nfnets_keras\nimport importlib\nimportlib.reload(nfnets_keras)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import importlib\nimportlib.reload(nfnets_keras)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!pip install git+https://github.com/prateekkrjain/nfnets-keras","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from efficientnet.keras import EfficientNetB5,EfficientNetB4\nimport h5py\n#from nfnets_keras import NFNetF0\n#from  tfnfnet.nfnet import NFNet\nfrom keras.utils.conv_utils import convert_kernel\n# Function to create our EfficientNetB3 model\ndef premodel():\n        inp = tf.keras.layers.Input(shape = (*IMAGE_SIZE, 3), name = 'inp1')\n        label = tf.keras.layers.Input(shape = (), name = 'inp2')\n        x = EfficientNetB4(weights=None, include_top = False)(inp)\n        #x=tf.keras.applications.DenseNet201(include_top = False)(inp)\n        #x = NFNet(\n        #num_classes=1000,\n        #variant=\"F0\",\n        #label_smoothing=0,\n        #)(inp)\n        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n        x= tf.keras.layers.BatchNormalization()(x)\n        #x=tf.keras.applications.ResNet50(weights='imagenet',include_top=False,classes=N_CLASSES)(inp);\n        x = tf.keras.layers.Dense(N_CLASSES)(x)\n        #x=cos_loss(x,label,N_CLASSES)\n        #x = margin([x, label])\n        #output=ArcFaceLayer0(N_CLASSES)(x)\n        output = tf.keras.layers.Softmax(dtype='float32')(x)\n        embeddingmodel = tf.keras.models.Model(inputs = [inp, label], outputs = [output])\n        #x=tf.keras.applications.ResNet50(weights='imagenet',include_top=False,classes=N_CLASSES)(inp);\n        #x = tf.keras.layers.Dense(N_CLASSES)(x)\n        #x=cos_loss(x,label,N_CLASSES)\n        #output=ArcFaceLayer0(N_CLASSES)(x)\n        weights_path = '../input/effb4base/effnetB4-sam.h5'\n        #before=get_model2()\n        embeddingmodel.load_weights(weights_path)\n        return embeddingmodel\n#pre_model=premodel()\n\nclass SAMModel(tf.keras.models.Model):\n    def train_step(self, data):\n        return sam_train_step(self, data)\nimport gc\ndef get_model(ss=10,mm=0.5):\n    with strategy.scope():\n        adacos=AdaCos(N_CLASSES, name='AdaCos', )\n        inp = tf.keras.layers.Input(shape = (*IMAGE_SIZE, 3), name = 'inp1')\n        label = tf.keras.layers.Input(shape = (), name = 'inp2')\n        #x=tf.keras.applications.DenseNet201(include_top = False)(inp)\n        x = EfficientNetB4(weights='noisy-student', include_top = False)(inp)\n        #x = EfficientNetB5(weights=None, include_top = False)(inp)\n        #x = NFNet(\n        ##num_classes=1000,\n        #variant=\"F0\",\n        #label_smoothing=0,\n        #)(inp)\n        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n        x= tf.keras.layers.BatchNormalization()(x)\n        #x=tf.keras.applications.ResNet50(weights='imagenet',include_top=False,classes=N_CLASSES)(inp);\n        #x = tf.keras.layers.Dense(N_CLASSES)(x)\n        #x=cos_loss(x,label,N_CLASSES)\n        x = adacos((x,label),True)#margin([x, label])\n        #output=ArcFaceLayer0(N_CLASSES)(x)\n        output = tf.keras.layers.Softmax(dtype='float32')(x)\n        model = SAMModel(inputs = [inp, label], outputs = [output])\n        pre=premodel()\n        model.layers[1].set_weights(pre.layers[1].get_weights())\n        print('Model loaded.')\n        del pre\n        gc.collect()\n\n        opt = tf.keras.optimizers.Adam(learning_rate = LR)\n        radam = tfa.optimizers.RectifiedAdam()\n        sgd=tf.keras.optimizers.SGD(learning_rate=LR)\n        #tf.keras.losses.CosineSimilarity() tf.keras.losses.SparseCategoricalCrossentropy()\n        model.compile(\n            optimizer = radam,\n            loss = [tf.keras.losses.SparseCategoricalCrossentropy()],\n            metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n            ) \n        \n        return model\ndef get_model2():\n    with strategy.scope():\n        inp = tf.keras.layers.Input(shape = (*IMAGE_SIZE, 3),name='inp1')\n        label = tf.keras.layers.Input(shape = (), name = 'inp2')\n        x =EfficientNetB4(weights='noisy-student', include_top = False)(inp)\n        #x=tf.keras.applications.DenseNet201(include_top = False)(inp)\n        #x = nfnets_keras.NFNetF0(num_classes=1000,include_top=False)(inp)\n        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n        x= tf.keras.layers.BatchNormalization()(x)\n        x = tf.keras.layers.Dense(N_CLASSES)(x)\n        #x=cos_loss(x,label,N_CLASSES)\n        #x = margin([x, label])\n        #output=ArcFaceLayer0(N_CLASSES)(x)\n        output = tf.keras.layers.Softmax(dtype='float32')(x)\n        model = SAMModel(inputs = [inp,label], outputs = [output])\n        opt = tf.keras.optimizers.Adam(learning_rate = LR)\n        radam = tfa.optimizers.RectifiedAdam()\n        sgd=tf.keras.optimizers.SGD()\n        #tf.keras.losses.CosineSimilarity() tf.keras.losses.SparseCategoricalCrossentropy()\n        model.compile(\n            optimizer = radam,\n            loss = [tf.keras.losses.SparseCategoricalCrossentropy()],\n            metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n            ) \n        \n        return model\n\ndef train_and_evaluate(save_file=f'EfficientNetB5_adacos_512_42.h5',mixup=False):\n    # Seed everything\n    seed_everything(SEED)\n    print('\\n')\n    print('-'*50)\n    train, valid = train_test_split(TRAINING_FILENAMES, shuffle = True, random_state = SEED)\n    train_dataset = get_training_dataset(train, ordered = False,mixup=mixup)\n    val_dataset = get_validation_dataset(valid, ordered = True,mixup=mixup)\n    STEPS_PER_EPOCH = count_data_items(train) // BATCH_SIZE\n    del train\n    del valid\n    if(mixup==False):\n        train_dataset = train_dataset.map(lambda posting_id, image, label_group, matches: (image, label_group))\n        val_dataset = val_dataset.map(lambda posting_id, image, label_group, matches: (image, label_group))\n    else:\n        train_dataset = train_dataset.map(lambda posting_id, image, label_group, matches: image)\n        val_dataset = val_dataset.map(lambda posting_id, image, label_group, matches: image)\n        \n    #K.clear_session()\n    #model=get_model()\n    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=1, min_lr=0.00001,verbose=1)\n    # Model checkpoint\n    early_stop = EarlyStopping(monitor = 'val_loss', min_delta = 0.001, \n                              patience = 3, mode = 'min', verbose = 1,\n                           restore_best_weights = True)\n    checkpoint = tf.keras.callbacks.ModelCheckpoint(save_file, \n                                                    monitor = 'val_loss', \n                                                    save_best_only = True,\n                                                    save_weights_only = True, \n                                                    mode = 'min')\n    #, get_lr_callback()\n    history = model.fit(train_dataset,\n                        steps_per_epoch = STEPS_PER_EPOCH,\n                        epochs = EPOCHS,\n                        callbacks = [early_stop,reduce_lr,checkpoint], \n                        validation_data = val_dataset,\n                        )\n    del train_dataset\n    del val_dataset\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#m=SAMModel()\n#print(pre_model.layers)\nBATCH_SIZE = 32 * strategy.num_replicas_in_sync","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#K.clear_session()\n#model = get_model2()\n#model.summary()\n#train_and_evaluate(f'effnetB4-sam.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\nK.clear_session()\ngc.collect()\nmodel = get_model(ss=64,mm=0.7)\n#model.layers[1].tranable=False\ntrain_and_evaluate()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold,StratifiedKFold\nimport math, re, os\nimport gc\nimport tensorflow as tf\n#from tensorflow.keras.layers import *\nimport numpy as np\nfrom tensorflow import keras\nfrom functools import partial\n\nfrom tensorflow.keras.applications.imagenet_utils import decode_predictions\nimport tensorflow_addons as tfa\nFOLD=4\nkf =  KFold(n_splits=FOLD, shuffle=True, random_state = SEED)\n#GCS_PATH = '/kaggle/input/cassava-leaf-disease-tfrecords-center-512x512'\ni=0\n#for n_fold, (train, test) in enumerate(cv.split(X)):\n\nfor train_index, test_index in kf.split(TRAINING_FILENAMES):\n    K.clear_session()\n    gc.collect()\n    model = get_model(ss=20,mm=0.7)\n    seed_everything(SEED)\n        \n    train, valid = [TRAINING_FILENAMES[i] for i in train_index],[TRAINING_FILENAMES[i] for i in test_index]#train_test_split(TRAINING_FILENAMES, shuffle = True, random_state = SEED)\n    print(f'fold={i}')\n    train_dataset = get_training_dataset(train, ordered = False)\n    train_dataset = train_dataset.map(lambda posting_id, image, label_group, matches: (image, label_group))\n    val_dataset = get_validation_dataset(valid, ordered = True)\n    val_dataset = val_dataset.map(lambda posting_id, image, label_group, matches: (image, label_group))\n    STEPS_PER_EPOCH = count_data_items(train) // BATCH_SIZE\n    del train\n    del valid\n    #K.clear_session()\n    #model=get_model()\n    # Model checkpoint\n    save_file=f'eff_adacos_model_fold{i}.h5'\n    i+=1\n    early_stop = EarlyStopping(monitor = 'val_loss', min_delta = 0.001, \n                              patience = 3, mode = 'min', verbose = 1,\n                           restore_best_weights = True)\n    checkpoint = tf.keras.callbacks.ModelCheckpoint(save_file, \n                                                    monitor = 'val_loss', \n                                                    save_best_only = True,\n                                                    save_weights_only = True, \n                                                    mode = 'min')\n    #, get_lr_callback()\n    history = model.fit(train_dataset,\n                        steps_per_epoch = STEPS_PER_EPOCH,\n                        epochs = EPOCHS,\n                        callbacks = [checkpoint,early_stop,get_lr_callback()], \n                        validation_data = val_dataset,\n                        )\n    del train_dataset\n    del val_dataset\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BiTemperedLogisticLoss(tf.keras.losses.Loss):\n    def __init__(self, t1, t2, lbl_smth, n_iter,weights):\n      super(BiTemperedLogisticLoss, self).__init__()\n      self.t1 = t1\n      self.t2 = t2\n      self.weights=weights\n      self.lbl_smth = lbl_smth\n      self.n_iter = n_iter\n\n    def call(self, y_true, y_pred):\n        nb_cl = len(self.weights)\n        final_mask = K.zeros_like(y_pred[:, 0])\n        y_pred_max = K.max(y_pred, axis=1)\n        y_pred_max = K.reshape(y_pred_max, (K.shape(y_pred)[0], 1))\n        y_pred_max_mat = K.equal(y_pred, y_pred_max)\n        for c_p, c_t in product(range(nb_cl), range(nb_cl)):\n            final_mask += (self.weights[c_t, c_p] * y_pred_max_mat[:, c_p] * y_true[:, c_t])\n        return bi_tempered_logistic_loss(y_pred, y_true, self.t1, self.t2, self.lbl_smth, self.n_iter) * final_mask\ndef w_bi_tempered_logistic_loss(y_true, y_pred,weights,t1,t2,label_smoothing=0,n_iter=5 ):\n        if(weights==None):\n            return bi_tempered_logistic_loss(y_pred, y_true,t1,t2,label_smoothing,n_iter)\n        nb_cl = len(weights)\n        final_mask = K.zeros_like(y_pred[:, 0])\n        y_pred_max = K.max(y_pred, axis=1)\n        y_pred_max = K.reshape(y_pred_max, (K.shape(y_pred)[0], 1))\n        y_pred_max_mat = K.equal(y_pred, y_pred_max)\n        for c_p, c_t in product(range(nb_cl), range(nb_cl)):\n            final_mask += (weights[c_t, c_p] * y_pred_max_mat[:, c_p] * y_true[:, c_t])\n        return bi_tempered_logistic_loss(y_pred, y_true,t1,t2,label_smoothing,n_iter) * final_mask\nclass WeightBiTemperedLogisticLoss( keras.losses.CategoricalCrossentropy):\n        def __init__(self,\n                   from_logits=False,\n                   label_smoothing=0,\n                   reduction=keras.losses.Reduction.AUTO,\n                   name='w_bi_tempered_logistic_loss',\n                   t1=1.0,\n                   t2=1.0,\n                   weights=None):\n            @dispatch.add_dispatch_support\n            def loss_fun():\n              return  partial(w_bi_tempered_logistic_loss, t1=t1,t2=t2,weights= weights)\n            super().__init__(\n            loss_fun,\n            name=name,\n            label_smoothing=label_smoothing\n            )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os \nos.chdir('/kaggle/working')\nfrom IPython.display import FileLink \nFileLink('./effnetB4-sam.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os \nos.chdir('/kaggle/working')\nfrom IPython.display import FileLink \nFileLink('./eff_adacos_model_fold3.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}